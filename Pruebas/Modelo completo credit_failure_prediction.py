# -*- coding: utf-8 -*-
"""Rev.6 - 1-Limpieza Datos y Feature_Credit failure prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z-CUbk-R5nvjH9H4Dz-1Ti8CUVsvbQsS

# Indice proyecto Predictor creditos bancarios:
* **0- Datos + EDA Credit failure prediction**
  * Link: https://colab.research.google.com/drive/1OEB_xe0QN__ABY8uueQnofnQszqlZkP2?usp=sharing

* **1-Limpieza Datos y Feature Credit failure prediction**
    * Link:https://colab.research.google.com/drive/1z-CUbk-R5nvjH9H4Dz-1Ti8CUVsvbQsS?usp=sharing
    
**Nota**: Al inicio del proyecto se  guardo el archivo original con nombre *cs-training.csv y cs-test.csv* en local y se continúa trabajando con la copia del archivo llamada *cs-training.csv.*

# Predicción de Impagos Hipotecarios con Machine Learning

### Objetivo del Proyecto

El objetivo de este proyecto es desarrollar un modelo predictivo que permita identificar posibles impagos en créditos hipotecarios, utilizando técnicas avanzadas de Machine Learning.

Aunque se trata de un caso simulado, los datos provienen del conjunto **"Give Me Some Credit"** publicado en [Kaggle](https://www.kaggle.com/c/GiveMeSomeCredit), ampliamente utilizado para problemas de scoring crediticio.

Este dataset permite replicar un escenario realista del sector financiero y practicar con un flujo completo de modelado: desde la limpieza de datos hasta la puesta en producción.

Se ha aplicado un enfoque integral con balanceo de clases, selección de modelos basados en boosting y ensamblado de algoritmos para mejorar la capacidad predictiva.


### Enfoque y Técnicas Aplicadas

- **Limpieza estructurada de datos** mediante un `Pipeline` modular.
- **Exploración de correlaciones** para comprender las variables más relevantes.
- **Balanceo de clases** con **SMOTE** ante un fuerte desbalance en la variable objetivo.
- **Modelado con algoritmos de boosting**: `XGBoost`, `LightGBM` y `CatBoost`.
- **Optimización automática de hiperparámetros** con `Optuna` para afinar el rendimiento.
- **Modelo ensamblado** mediante `VotingClassifier` para combinar fortalezas de distintos algoritmos.
- **Ajuste del umbral de decisión** para mejorar el trade-off entre `precision` y `recall`.

### Evaluación y Métricas
Los modelos fueron evaluados con métricas clave:

- `ROC AUC`
- `Precision`
- `Recall`
- `F1-score`

Esto permitió ajustar el modelo a objetivos específicos del negocio, como **minimizar falsos negativos** (clientes morosos no detectados) sin penalizar excesivamente la precisión.

### Evaluación y Métricas

Los modelos han sido evaluados con las siguientes métricas clave:

| **Modelo**                                         | **Precision** | **Recall** | **F1-score** | **ROC AUC** |
|----------------------------------------------------|--------------|-----------|-------------|------------|
| VotingClassifier (XGB + CatBoost, umbral = 0.57)  | 0.3229       | 0.5922    | 0.4179      | 0.8591     |
| CatBoost                                         | 0.3834       | 0.4873    | 0.4291      | 0.8585     |
| XGBoost                                          | 0.2673       | 0.6677    | 0.3818      | 0.8570     |
| LightGBM                                         | 0.3383       | 0.5362    | 0.4148      | 0.8549     |

El modelo **VotingClassifier (XGB + CatBoost, umbral = 0.57)** ha sido seleccionado para guardar, ya que presenta **el mejor desempeño en términos de ROC AUC (0.8591)** y mantiene un **buen equilibrio entre precisión y recall**. Este enfoque garantiza la correcta identificación de clientes morosos, minimizando falsos negativos sin sacrificar precisión.
"""

#@title **1.Importación de librerías para análisis, modelos y métricas Credit failure prediction**

#Instalar librerías Boosting (XGBoost, LightGBM y CatBoost)
!pip install -q pandas numpy scikit-learn xgboost lightgbm catboost imbalanced-learn shap matplotlib seaborn joblib

#Instalar optuna
!pip install optuna catboost xgboost lightgbm --quiet

# Manipulación de datos
import pandas as pd  # Procesar, analizar y limpiar datos
import numpy as np  # Operaciones matemáticas y manipulación de matrices

# Visualización de datos
import seaborn as sns  # Visualización de gráficos estadísticos
import matplotlib.pyplot as plt  # Generación de gráficos

# Preprocesamiento y escalado
from sklearn.model_selection import train_test_split  # División en Train/Test
from sklearn.preprocessing import StandardScaler, RobustScaler  # Normalización y escalado
from sklearn.compose import ColumnTransformer  # Transformaciones por columnas
from sklearn.base import BaseEstimator, TransformerMixin # Creación de transformadores personalizados
import optuna # Optimización de hiperparámetros

# Modelos de clasificación (Boosting)
from xgboost import XGBClassifier  # Boosting optimizado
from lightgbm import LGBMClassifier  # Boosting eficiente en grandes datos
from catboost import CatBoostClassifier  # Boosting robusto para datos categóricos

# Evaluación de modelos
from sklearn.metrics import (
    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report
)
from sklearn.ensemble import VotingClassifier # Combinación de modelos

# Balanceo de datos desbalanceados
from imblearn.over_sampling import SMOTE  # Técnica para generar datos sintéticos en clases minoritarias

# Interpretabilidad del modelo
import shap  # Explicación de impacto de características en modelos

# Gestión de almacenamiento
import joblib  # Guardado y carga de modelos entrenados

print("Librerías cargadas correctamente.")

#@title 2.Importar csv para limpieza
from limpieza_basica import LimpiezaBasica
df = pd.read_csv("cs-training.csv")
df_limpio = LimpiezaBasica().fit_transform(df)

#@title 3.Division datos X - Y
from division_datos import dividir_datos

X_train, X_test, y_train, y_test = dividir_datos(df_limpio)

#@title 4.Preprocesamiento: Winsorización + Escalado + SMOTE
from preprocesamiento import preprocesar_datos

columnas_winsor = ['Edad', 'UsoCrédito', 'IngresoMensual', 'RatioDeuda',
                   '30-59DíasTarde', '60-89DíasTarde', '90DíasTarde',
                   'PréstamosCasa', 'LíneasCrédito', 'Dependientes']

X_train_final, y_train_final, X_test_scaled, scaler = preprocesar_datos(X_train, X_test, y_train, columnas_winsor)

"""#Boosting Models"""

#@title Instalar librerías Boosting (XGBoost, LightGBM y CatBoost)

#!pip install -q xgboost lightgbm catboost

#@title 5.Definir modelos XGBC, LGBMC, CatBoost
#import numpy as np
#import pandas as pd
#from xgboost import XGBClassifier
#from lightgbm import LGBMClassifier
#from catboost import CatBoostClassifier
#from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

# Definir modelos con parámetros optimizados
modelos = {
    'XGBoost': XGBClassifier(
        n_estimators=250, learning_rate=0.03, max_depth=3,  # Ajustamos profundidad y estabilidad
        min_child_weight=10, gamma=2,  # Reducimos falsos positivos
        eval_metric='error', scale_pos_weight=1.5,  # Ajustamos peso de clases
        tree_method='hist', predictor='cpu_predictor',  # Configuración para CPU
        use_label_encoder=False, verbosity=0, random_state=42
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=200, learning_rate=0.05, max_depth=4,  # Mantiene estabilidad
        num_leaves=50, min_data_in_leaf=50, min_child_samples=30,  # Ajuste para evitar sobreajuste
        class_weight='balanced', device='cpu', verbosity=-1, random_state=42
    ),
    'CatBoost': CatBoostClassifier(
        iterations=200, learning_rate=0.05, depth=4, verbose=0, random_state=42  # Configuración óptima
    )
}

# Entrenar y evaluar cada modelo
resultados = []
for nombre, modelo in modelos.items():
    modelo.fit(X_train_final, y_train_final)  # Entrenamiento

    y_proba = modelo.predict_proba(X_test_scaled)[:, 1]  # Probabilidades clase positiva
    threshold = 0.6 if nombre == "XGBoost" else 0.5  # Ajuste de umbral solo para XGBoost
    y_pred = (y_proba >= threshold).astype(int)

    # Calcular métricas de evaluación
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)

    # Guardar resultados
    resultados.append({
        "Modelo": nombre,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-score": round(f1, 4),
        "ROC AUC": round(auc, 4)
    })

# Mostrar ranking de resultados ordenados por ROC AUC
df_resultados = pd.DataFrame(resultados).sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)
display(df_resultados)

#@title 6.Código completo: Optuna + VotingClassifier + Evaluación Soft
# 1. Instalación
#!pip install optuna catboost xgboost lightgbm --quiet

# 2. Imports
#import optuna
#from xgboost import XGBClassifier
#from catboost import CatBoostClassifier
#from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
#from sklearn.model_selection import train_test_split
#from sklearn.ensemble import VotingClassifier
#import pandas as pd

# 3. Reducir conjunto para optimización (más rápido)
X_train_opt, _, y_train_opt, _ = train_test_split(X_train_final, y_train_final, train_size=0.5, random_state=42)

# 4. Función Optuna
def objective(trial, model_name):
    if model_name == "XGBoost":
        params = {
            "n_estimators": trial.suggest_int("n_estimators", 100, 300),
            "max_depth": trial.suggest_int("max_depth", 3, 6),
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.2),
            "subsample": trial.suggest_float("subsample", 0.5, 1.0),
            "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
            "scale_pos_weight": trial.suggest_float("scale_pos_weight", 1.0, 3.0),
            "eval_metric": "auc",
            "use_label_encoder": False,
            "random_state": 42,
            "verbosity": 0
        }
        model = XGBClassifier(**params)

    elif model_name == "CatBoost":
        params = {
            "iterations": trial.suggest_int("iterations", 100, 300),
            "depth": trial.suggest_int("depth", 3, 6),
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.2),
            "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1, 5),
            "random_state": 42,
            "verbose": 0
        }
        model = CatBoostClassifier(**params)

    model.fit(X_train_opt, y_train_opt)
    y_proba = model.predict_proba(X_test_scaled)[:, 1]
    return roc_auc_score(y_test, y_proba)

# 5. Optimización
studies = {}
for modelo in ["XGBoost", "CatBoost"]:
    study = optuna.create_study(direction="maximize")
    study.optimize(lambda trial: objective(trial, modelo), n_trials=25, n_jobs=-1)
    studies[modelo] = study
    print(f"\n Mejor configuración para {modelo}:")
    print(study.best_params)

# 6. Recuperar mejores parámetros
best_params_xgb = studies["XGBoost"].best_params
best_params_cat = studies["CatBoost"].best_params

# 7. VotingClassifier con mejores parámetros
voting_model = VotingClassifier(
    estimators=[
        ('xgb', XGBClassifier(**best_params_xgb, eval_metric='auc', use_label_encoder=False, random_state=42)),
        ('cat', CatBoostClassifier(**best_params_cat, verbose=0, random_state=42))
    ],
    voting='soft' # Cambiar a 'hard' si deseas votación dura
)

voting_model.fit(X_train_final, y_train_final)

# 8. Evaluar con umbral ajustado
threshold = 0.57  # puedes cambiar este valor si lo deseas
y_proba = voting_model.predict_proba(X_test_scaled)[:, 1]
y_pred = (y_proba >= threshold).astype(int)

# 9. Métricas
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_proba)

print(f"\n VotingClassifier (XGB + CatBoost, umbral = {threshold})")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"ROC AUC:   {roc_auc:.4f}")

#@title 7.Guardar el modelo final
import joblib

# Guardar el modelo final VotingClassifier
joblib.dump(voting_model, "modelo_voting.pkl")

# Guardar el escalador RobustScaler si fue utilizado
joblib.dump(scaler, "scaler_robust.pkl")

print("Modelo y escalador guardados correctamente en el entorno de trabajo.")