# -*- coding: utf-8 -*-
"""5.Definir modelos XGBC, LGBMC, CatBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lu_snSA4b1Z0Ejs0eOaJE5mmu0-hDORn

#Boosting Models
"""

#@title Instalar librerías Boosting (XGBoost, LightGBM y CatBoost)

#!pip install -q xgboost lightgbm catboost

#@title 5.Definir modelos XGBC, LGBMC, CatBoost
#import numpy as np
#import pandas as pd
#from xgboost import XGBClassifier
#from lightgbm import LGBMClassifier
#from catboost import CatBoostClassifier
#from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

# Definir modelos con parámetros optimizados
modelos = {
    'XGBoost': XGBClassifier(
        n_estimators=250, learning_rate=0.03, max_depth=3,  # Ajustamos profundidad y estabilidad
        min_child_weight=10, gamma=2,  # Reducimos falsos positivos
        eval_metric='error', scale_pos_weight=1.5,  # Ajustamos peso de clases
        tree_method='hist', predictor='cpu_predictor',  # Configuración para CPU
        use_label_encoder=False, verbosity=0, random_state=42
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=200, learning_rate=0.05, max_depth=4,  # Mantiene estabilidad
        num_leaves=50, min_data_in_leaf=50, min_child_samples=30,  # Ajuste para evitar sobreajuste
        class_weight='balanced', device='cpu', verbosity=-1, random_state=42
    ),
    'CatBoost': CatBoostClassifier(
        iterations=200, learning_rate=0.05, depth=4, verbose=0, random_state=42  # Configuración óptima
    )
}

# Entrenar y evaluar cada modelo
resultados = []
for nombre, modelo in modelos.items():
    modelo.fit(X_train_final, y_train_final)  # Entrenamiento

    y_proba = modelo.predict_proba(X_test_scaled)[:, 1]  # Probabilidades clase positiva
    threshold = 0.6 if nombre == "XGBoost" else 0.5  # Ajuste de umbral solo para XGBoost
    y_pred = (y_proba >= threshold).astype(int)

    # Calcular métricas de evaluación
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)

    # Guardar resultados
    resultados.append({
        "Modelo": nombre,
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1-score": round(f1, 4),
        "ROC AUC": round(auc, 4)
    })

# Mostrar ranking de resultados ordenados por ROC AUC
df_resultados = pd.DataFrame(resultados).sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)
display(df_resultados)